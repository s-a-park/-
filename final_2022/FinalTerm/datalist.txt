아이디 이름 설명 링크 카테 필드 테스크 데이터수

data_wiki[29] = ["nyu_depth_v1_v2","nyu depth V1"," V2","-","https://cs.nyu.edu","Image","Semantic Segmentation","-","-","30","-"];
data_wiki[30] = ["lip","lip","The LIP (Look into Person) dataset is a large-scale dataset focusing on semantic understanding of a person. It contains 50","00 images with elaborated pixel-wise annotations of 19 semantic human part labels and 2D human poses with 16 key points. The images...","http://sysu-hcp.net/lip/index.php","Image","Semantic Segmentation","Semantic_Segmentation","-","31","-"];
data_wiki[31] = ["ade","ADE","The ADE20K semantic segmentation dataset contains more than 20K scene-centric images exhaustively annotated with pixel-level objects and object parts labels. There are totally 150 semantic categories"," which include stuffs like sky"," road"," grass"," and discr...","https://groups.csail.mit.edu/vision/datasets/ADE20K/index.html","Image","Semantic Segmentation","Semantic_Segmentation","Image-to-Image_Translation","Scene_Understanding","-","32","-"];
data_wiki[32] = ["ffhq","ffhq","Flickr-Faces-HQ (FFHQ) consists of 70","000 high-quality PNG images at 1024×1024 resolution and contains considerable variation in terms of age"," ethnicity and image background. It also has good coverage of accessories such as eyeglasses"," sunglasses"," hats","...","https://github.com/NVlabs/ffhq-dataset","Image","Super Resolution","Image_Generation","Image_Super-Resolution","Image_Inpainting","-","33","-"];
data_wiki[33] = ["ucf","ucf","UCF101 dataset is an extension of UCF50 and consists of 13","320 video clips"," which are classified into 101 categories. These 101 categories can be classified into 5 types (Body motion"," Human-human interactions"," Human-object interactions"," Playing musical i...","https://www.crcv.ucf.edu/data/UCF101.php#Results_on_UCF101","Video","Action Recognition","Temporal_Action_Localization","Action_Recognition","Action_Detection","-","1","-"];
data_wiki[34] = ["activitynet","Activitynet","The ActivityNet dataset contains 200 different types of activities and a total of 849 hours of videos collected from YouTube. ActivityNet is the largest benchmark for temporal activity detection to date in terms of both the number of activity categories ...","http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html","Video","Action Recognition","Temporal_Action_Localization","Action_Recognition","Action_Classification","-","2","-"];
data_wiki[35] = ["ntu","ntu","-","http://rose1.ntu.edu.sg/datasets/actionrecognition.asp","Video","Action Recognition","-","-","3","-"];
data_wiki[36] = ["kinetics","kinetics","The Kinetics dataset is a large-scale"," high-quality dataset for human action recognition in videos. The dataset consists of around 500","000 video clips covering 600 human action classes with at least 600 video clips for each action class. Each video clip ...","https://arxiv.org/abs/1705.06950","Video","Action Recognition","Temporal_Action_Localization","Video_Classification","Action_Recognition","-","4","-"];
data_wiki[37] = ["youtube_8m_segments_dataset","YouTube-8M Segments Dataset","The YouTube-8M dataset is a large scale video dataset"," which includes more than 7 million videos with 4716 classes labeled by the annotation system. The dataset consists of three parts: training set"," validate set"," and test set. In the training set"," each ...","http://research.google.com/youtube8m/index.html","Video","Classification","Video_Classification","Video_Prediction","8 million","5","-"];
data_wiki[38] = ["davis_16","davis 16","DAVIS16 is a dataset for video object segmentation which consists of 50 videos in total (30 videos for training and 20 for testing). Per-frame pixel-wise annotations are offered.","https://davischallenge.org/index.html","Video","Object Segmentation","Video_Object_Segmentation","Video_Salient_Object_Detection","Unsupervised_Video_Object_Segmentation","-","6","-"];
data_wiki[39] = ["davis_17","davis 17","DAVIS17 is a dataset for video object segmentation. It contains a total of 150 videos - 60 for training"," 30 for validation"," 60 for testing","https://davischallenge.org/index.html","Video","Object Segmentation","Semantic_Segmentation","Video_Object_Segmentation","Referring_Expression_Segmentation","-","7","-"];
data_wiki[40] = ["davis_18","davis 18","-","https://davischallenge.org/index.html","Video","Object Segmentation","-","-","8","-"];
data_wiki[41] = ["davis_19","davis 19","-","https://davischallenge.org/index.html","Video","Object Segmentation","-","-","9","-"];
data_wiki[42] = ["mot","MOT","-","https://motchallenge.net/","Video","Object Tracking","-","-","10","-"];
data_wiki[43] = ["vot","vot","-","https://www.votchallenge.net/index.html","Video","Object Tracking","-","-","11","-"];
data_wiki[44] = ["dexter","dexter","-","http://archive.ics.uci.edu/ml//datasets/Dexter","Text","Classification","-","2600","1","-"];
data_wiki[45] = ["ubuntu_dialogue","ubuntu dialogue","Ubuntu Dialogue Corpus (UDC) is a dataset containing almost 1 million multi-turn dialogues"," with a total of over 7 million utterances and 100 million words. This provides a unique resource for research into building dialogue managers based on neural lang...","https://ubuntudialogue.org/","Text","Dialogue Generation","Dialogue_Generation","Conversational_Response_Selection","Answer_Selection","-","2","-"];
data_wiki[46] = ["wmt19","wmt19","-","http://www.statmt.org/wmt19/","Text","Machine Translation","-","-","3","-"];
data_wiki[47] = ["wmt18","wmt18","WMT 2018 is a collection of datasets used in shared tasks of the Third Conference on Machine Translation. The conference builds on a series of twelve previous annual workshops and conferences on Statistical Machine Translation.    The conference featured...","http://www.statmt.org/wmt18/papers.html","Text","Machine Translation","Machine_Translation","-","4","-"];
data_wiki[48] = ["wmt17","wmt17","-","http://www.statmt.org/wmt17/results.html","Text","Machine Translation","-","-","5","-"];
data_wiki[49] = ["wmt16","wmt16","WMT 2016 is a collection of datasets used in shared tasks of the First Conference on Machine Translation. The conference builds on ten previous Workshops on statistical Machine Translation.    The conference featured ten shared tasks:    a news translati...","http://www.statmt.org/wmt16/","Text","Machine Translation","Machine_Translation","Unsupervised_Machine_Translation","-","6","-"];
data_wiki[50] = ["wmt15","wmt15","WMT 2015 is a collection of datasets used in shared tasks of the Tenth Workshop on Statistical Machine Translation. The workshop featured five tasks:    a news translation task","  a metrics task","  a tuning task","  a quality estimation task","  an automatic p...","http://www.statmt.org/wmt15/","Text","Machine Translation","Machine_Translation","-","7","-"];
data_wiki[51] = ["wmt14","wmt14","WMT 2014 is a collection of datasets used in shared tasks of the Ninth Workshop on Statistical Machine Translation. The workshop featured four tasks:    a news translation task","  a quality estimation task","  a metrics task","  a medical text translation task.","http://www.statmt.org/wmt14/","Text","Machine Translation","Machine_Translation","Unsupervised_Machine_Translation","-","8","-"];
data_wiki[52] = ["semeval-2016","SemEval-2016","-","https://alt.qcri.org/semeval2016/index.php?id=tasks","Text","Word Sentiment","-","-","9","-"];
data_wiki[53] = ["bfm","BFM","-","https://faces.dmi.unibas.ch/bfm/?nav=1-0&id=basel_face_model","3-D Image","3-D Estimation","-","-","1","-"];
data_wiki[54] = ["pix3d","Pix3D","The Pix3D dataset is a large-scale benchmark of diverse image-shape pairs with pixel-level 2D-3D alignment. Pix3D has wide applications in shape-related tasks including reconstruction"," retrieval"," viewpoint estimation"," etc.","http://pix3d.csail.mit.edu/","3-D Image","Classification","3D_Shape_Reconstruction","3D_Shape_Modeling","3D_Shape_Classification","-","2","-"];
data_wiki[55] = ["shrec","shrec","The SHREC dataset contains 14 dynamic gestures performed by 28 participants (all participants are right handed) and captured by the Intel RealSense short range depth camera. Each gesture is performed between 1 and 10 times by each participant in two way:...","http://tosca.cs.technion.ac.il/book/shrec_robustness2010.html","3-D Image","Object Recognition","Gesture_Recognition","Hand_Gesture_Recognition","Skeleton_Based_Action_Recognition","-","3","-"];
data_wiki[56] = ["shapenetcore","shapenetCore","-","https://www.shapenet.org/","3-D Image","Semantic Segmentation","-","-","4","-"];
data_wiki[57] = ["faust","faust","The FAUST dataset is a dataset of real 3D scans of humans. It contains 10 scanned human shapes in 10 different poses"," resulting in a total of 100 non-watertight meshes with 6","890 nodes each.","http://faust.is.tue.mpg.de/","3-D Image","Semantic Segmentation","Semantic_Segmentation","3D_Reconstruction","3D_Point_Cloud_Matching","-","5","-"];
data_wiki[58] = ["scape","Scape","-","https://ai.stanford.edu/~drago/Projects/scape/scape.html","3-D Image","3-D Estimation","-","-","6","-"];
data_wiki[59] = ["voxceleb","VoxCeleb","-","http://www.robots.ox.ac.uk/~vgg/data/voxceleb/","Sound","Video Reconstruction","-","-","1","-"];